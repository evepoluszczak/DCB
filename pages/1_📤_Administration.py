"""
Page d'administration DCB - Gestion des donn√©es
"""

import streamlit as st
import os
import json
import zipfile
import tempfile
import shutil
from pathlib import Path
import sys

# Ajouter le dossier parent au path pour les imports
parent_dir = str(Path(__file__).parent.parent)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

st.set_page_config(
    page_title="Administration DCB",
    page_icon="üì§",
    layout="wide"
)

st.title("üì§ Administration - Gestion des donn√©es DCB")

st.markdown("""
Cette page permet de g√©rer les donn√©es de l'application DCB.

Il existe deux m√©thodes pour mettre √† jour les donn√©es :
1. **Upload de fichiers JSON** (recommand√© pour Streamlit Cloud)
2. **Ex√©cution du traitement** (n√©cessite acc√®s au r√©seau local)
""")

# Fonction pour obtenir le dossier Data Source
def get_data_source_folder():
    base_path = Path(__file__).parent.parent
    data_source = base_path / "Data Source"
    return data_source

# Tabs pour les diff√©rentes m√©thodes
tab1, tab2, tab3 = st.tabs(["üì§ Upload JSON", "‚öôÔ∏è Ex√©cuter le traitement", "üìä √âtat des donn√©es"])

# ========================
# TAB 1 : Upload de fichiers JSON
# ========================
with tab1:
    st.header("Upload de fichiers JSON")

    st.info("""
    **Processus recommand√© :**
    1. Ex√©cutez `Traitement_donnee.py` sur votre machine locale (avec acc√®s au r√©seau)
    2. Compressez le dossier `Data Source` en fichier ZIP
    3. Uploadez le fichier ZIP ici
    4. L'application extraira automatiquement les fichiers
    """)

    uploaded_file = st.file_uploader(
        "Choisir un fichier ZIP contenant le dossier 'Data Source'",
        type=['zip'],
        help="Le ZIP doit contenir un dossier 'Data Source' avec tous les sous-dossiers et fichiers JSON"
    )

    if uploaded_file is not None:
        st.success(f"Fichier upload√© : {uploaded_file.name} ({uploaded_file.size / 1024 / 1024:.2f} MB)")

        if st.button("üì¶ Extraire et installer les donn√©es", type="primary"):
            with st.spinner("Extraction en cours..."):
                try:
                    # Cr√©er un dossier temporaire
                    with tempfile.TemporaryDirectory() as temp_dir:
                        # Sauvegarder le ZIP
                        zip_path = Path(temp_dir) / "data.zip"
                        with open(zip_path, 'wb') as f:
                            f.write(uploaded_file.getbuffer())

                        # Extraire le ZIP
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(temp_dir)

                        # Trouver le dossier Data Source
                        data_source_path = None
                        for root, dirs, files in os.walk(temp_dir):
                            if 'Data Source' in dirs:
                                data_source_path = Path(root) / 'Data Source'
                                break
                            # Cas o√π on est directement dans Data Source
                            if Path(root).name == 'Data Source':
                                data_source_path = Path(root)
                                break

                        if data_source_path is None:
                            st.error("‚ùå Le dossier 'Data Source' n'a pas √©t√© trouv√© dans le ZIP")
                        else:
                            # Copier vers le dossier de l'application
                            target_path = get_data_source_folder()

                            # Cr√©er le dossier cible si n√©cessaire
                            target_path.parent.mkdir(parents=True, exist_ok=True)

                            # Supprimer l'ancien dossier Data Source s'il existe
                            if target_path.exists():
                                shutil.rmtree(target_path)

                            # Copier le nouveau
                            shutil.copytree(data_source_path, target_path)

                            st.success("‚úÖ Donn√©es install√©es avec succ√®s !")
                            st.info("üîÑ Actualisez la page principale pour voir les nouvelles donn√©es")

                            # Afficher un r√©sum√©
                            file_count = sum(1 for _ in target_path.rglob('*.json'))
                            st.metric("Fichiers JSON install√©s", file_count)

                            # Bouton pour effacer le cache
                            if st.button("üóëÔ∏è Effacer le cache et recharger"):
                                st.cache_data.clear()
                                st.rerun()

                except Exception as e:
                    st.error(f"‚ùå Erreur lors de l'extraction : {str(e)}")
                    st.exception(e)

    st.markdown("---")

    st.subheader("üì• Upload de fichiers individuels")
    st.warning("Option avanc√©e : upload de fichiers JSON individuels")

    col1, col2 = st.columns(2)

    with col1:
        st.selectbox(
            "Cat√©gorie",
            ["Demande", "Capacite/Aeroport", "Capacite/Planning", "Capacite/TempsProcess", "LevelOfService", "Annexe"]
        )

    with col2:
        uploaded_json = st.file_uploader(
            "Choisir un fichier JSON",
            type=['json'],
            key="individual_json"
        )

    if uploaded_json and st.button("üíæ Installer ce fichier"):
        st.info("Fonctionnalit√© √† impl√©menter")

# ========================
# TAB 2 : Ex√©cuter le traitement
# ========================
with tab2:
    st.header("‚öôÔ∏è Ex√©cuter le traitement des donn√©es")

    st.warning("""
    ‚ö†Ô∏è **Important** : Cette fonctionnalit√© ne peut s'ex√©cuter que sur une machine
    avec acc√®s au partage r√©seau `//gva.tld/aig/O/...`

    Sur Streamlit Cloud, cette fonctionnalit√© n'est pas disponible.
    """)

    # V√©rifier si on est en local ou sur Streamlit Cloud
    is_local = not os.path.exists('/mount/src')  # Streamlit Cloud utilise /mount/src

    if is_local:
        st.success("‚úÖ Vous √™tes en local - Le traitement peut √™tre ex√©cut√©")

        st.markdown("""
        ### Processus de traitement

        Le script va ex√©cuter les √©tapes suivantes :
        1. Traitement de la donn√©e historique
        2. Traitement de la donn√©e future
        3. Calcul des retards
        4. Calcul du nombre de mouvements par heure roulante
        5. Calcul des embarquements par tranche de 5 minutes
        6. Application des show-up profiles aux vols
        7. Transformation du planning s√ªret√©
        8. Calcul des plannings id√©aux (douane, s√ªret√©)
        9. Transformation de la donn√©e au format DCB app
        10. Transformation de la donn√©e au format PowerBI
        """)

        # V√©rifier que le chemin r√©seau est accessible
        network_path = "//gva.tld/aig/O/12_EM-DO/4_OOP/10_PERSONAL_FOLDERS/8_BASTIEN/DCB_Standalone_App/TraitementDonnee/Data/Input/WEBI"

        if st.button("üîç V√©rifier l'acc√®s au r√©seau"):
            if os.path.exists(network_path):
                st.success(f"‚úÖ Le chemin r√©seau est accessible : {network_path}")
            else:
                st.error(f"‚ùå Le chemin r√©seau n'est pas accessible : {network_path}")

        st.markdown("---")

        if st.button("‚ñ∂Ô∏è Lancer le traitement", type="primary"):
            st.warning("üöß Cette fonctionnalit√© sera impl√©ment√©e dans une prochaine version")
            st.info("""
            Pour l'instant, veuillez :
            1. Ex√©cuter `python Traitement_donnee.py` depuis le terminal
            2. Compresser le dossier `Data Source` r√©sultant
            3. Uploader le ZIP dans l'onglet "Upload JSON"
            """)
    else:
        st.error("""
        ‚ùå Vous √™tes sur Streamlit Cloud - Le traitement ne peut pas s'ex√©cuter ici

        **Solution :**
        1. Ex√©cutez `Traitement_donnee.py` sur votre machine locale
        2. Utilisez l'onglet "Upload JSON" pour uploader les r√©sultats
        """)

# ========================
# TAB 3 : √âtat des donn√©es
# ========================
with tab3:
    st.header("üìä √âtat actuel des donn√©es")

    data_source = get_data_source_folder()

    if not data_source.exists():
        st.error("‚ùå Le dossier 'Data Source' n'existe pas")
        st.info("Utilisez l'onglet 'Upload JSON' pour installer des donn√©es")
    else:
        st.success(f"‚úÖ Dossier Data Source trouv√© : `{data_source}`")

        # Analyser la structure
        st.subheader("Structure des dossiers")

        expected_folders = [
            "Demande/Actuel",
            "Capacite/Aeroport/Actuel",
            "Capacite/Planning/Actuel",
            "Capacite/TempsProcess/Actuel",
            "LevelOfService/Actuel",
            "Annexe/Actuel"
        ]

        for folder in expected_folders:
            folder_path = data_source / folder
            if folder_path.exists():
                json_files = list(folder_path.glob('*.json'))
                st.success(f"‚úÖ {folder} ({len(json_files)} fichiers JSON)")

                # Afficher les fichiers dans un expander
                with st.expander(f"Voir les fichiers de {folder}"):
                    for json_file in json_files:
                        file_size = json_file.stat().st_size / 1024  # KB
                        st.text(f"  üìÑ {json_file.name} ({file_size:.1f} KB)")
            else:
                st.error(f"‚ùå {folder} - Dossier manquant")

        # Statistiques globales
        st.markdown("---")
        st.subheader("Statistiques")

        total_json = sum(1 for _ in data_source.rglob('*.json'))
        total_size = sum(f.stat().st_size for f in data_source.rglob('*.json'))

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Fichiers JSON", total_json)
        with col2:
            st.metric("Taille totale", f"{total_size / 1024 / 1024:.2f} MB")
        with col3:
            # Trouver la date la plus r√©cente
            json_files = list(data_source.rglob('*.json'))
            if json_files:
                most_recent = max(json_files, key=lambda f: f.stat().st_mtime)
                import datetime
                mod_time = datetime.datetime.fromtimestamp(most_recent.stat().st_mtime)
                st.metric("Derni√®re modification", mod_time.strftime("%d/%m/%Y %H:%M"))

        # Bouton pour t√©l√©charger les donn√©es actuelles
        st.markdown("---")
        st.subheader("üíæ T√©l√©charger les donn√©es actuelles")

        if st.button("üì¶ Cr√©er un ZIP des donn√©es actuelles"):
            with st.spinner("Cr√©ation du ZIP..."):
                try:
                    # Cr√©er un ZIP en m√©moire
                    with tempfile.TemporaryDirectory() as temp_dir:
                        zip_path = Path(temp_dir) / "Data_Source.zip"

                        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                            for file in data_source.rglob('*'):
                                if file.is_file():
                                    arcname = file.relative_to(data_source.parent)
                                    zipf.write(file, arcname)

                        # Lire le ZIP
                        with open(zip_path, 'rb') as f:
                            zip_data = f.read()

                        st.download_button(
                            label="‚¨áÔ∏è T√©l√©charger Data_Source.zip",
                            data=zip_data,
                            file_name="Data_Source.zip",
                            mime="application/zip"
                        )

                        st.success("‚úÖ ZIP cr√©√© avec succ√®s!")

                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la cr√©ation du ZIP : {str(e)}")

st.markdown("---")
st.caption("Application DCB - Page d'administration")
